{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e509fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ Step 1: Load cleaned messages\n",
    "input_path = \"../data/processed/telegram_messages_20250621_052911_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# ğŸ§ª Step 2: Sample 50 tokenized messages\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_sample = df_shuffled.head(50)\n",
    "\n",
    "unlabeled_data = [{\"tokens\": eval(row[\"tokens\"])} for _, row in df_sample.iterrows()]\n",
    "\n",
    "# ğŸ‘€ Step 3: Show 5 for manual labeling\n",
    "print(\"\\nğŸ” Preview of messages for labeling:\\n\")\n",
    "for i, sample in enumerate(unlabeled_data[:5]):\n",
    "    print(f\"ğŸŸ¦ Sample {i+1}:\")\n",
    "    print(\"Tokens:\", sample[\"tokens\"])\n",
    "    print()\n",
    "\n",
    "# âœï¸ Step 4: Add your labels manually here\n",
    "# For each labeled example, ensure:\n",
    "#   - token list length == label list length\n",
    "#   - BIO labels use the format B-TAG, I-TAG, O\n",
    "\n",
    "labeled_data = [\n",
    "    {\n",
    "        \"tokens\": [\"áˆˆáˆáŒ†á‰½\", \"áŒ«áˆ›\", \"á‰ \", \"350\", \"á‰¥áˆ­\"],\n",
    "        \"labels\": [\"B-PRODUCT\", \"I-PRODUCT\", \"O\", \"B-PRICE\", \"I-PRICE\"]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\"á‰ áŠ á‹²áˆµ\", \"áŠ á‰ á‰£\", \"á‹¨áˆšáŒˆáŠ\", \"áˆ˜áŠªáŠ“\"],\n",
    "        \"labels\": [\"B-LOC\", \"I-LOC\", \"O\", \"B-PRODUCT\"]\n",
    "    }\n",
    "    # ğŸ” Copy more token sets from `unlabeled_data` and annotate them\n",
    "]\n",
    "\n",
    "# ğŸ’¾ Step 5: Save to CoNLL format\n",
    "def save_conll(data, filepath):\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            for token, label in zip(item[\"tokens\"], item[\"labels\"]):\n",
    "                f.write(f\"{token}\\t{label}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"âœ… Saved {len(data)} labeled samples to: {filepath}\")\n",
    "\n",
    "# ğŸ’½ Step 6: Export annotated data\n",
    "save_conll(labeled_data, \"data/labeled/amharic_ner.conll\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ“¦ Imports\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "os.makedirs(\"data/unlabeled\", exist_ok=True)\n",
    "\n",
    "\n",
    "# ğŸ“¥ Load tokenized unlabeled data\n",
    "df = pd.read_pickle(\"data/unlabeled/unlabeled_data.pkl\")  # Or replace with your variable\n",
    "\n",
    "# ğŸ”¢ Number of samples to label\n",
    "NUM_TO_LABEL = 5  # You can increase as needed\n",
    "\n",
    "# ğŸ“ Define available tags\n",
    "label_options = [\"B-PRODUCT\", \"I-PRODUCT\", \"B-LOC\", \"I-LOC\", \"B-PRICE\", \"I-PRICE\", \"O\"]\n",
    "\n",
    "# ğŸ§  Initialize labeled data container\n",
    "labeled_data = []\n",
    "\n",
    "# ğŸ§° Labeling function\n",
    "def label_sample(tokens):\n",
    "    print(f\"\\nğŸŸ¨ Tokens to label: {' '.join(tokens)}\\n\")\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        print(f\"Token: {token}\")\n",
    "        print(\"Available Tags: \", label_options)\n",
    "        label = input(\"Enter label: \").strip().upper()\n",
    "        while label not in label_options:\n",
    "            label = input(\"Invalid label. Try again: \").strip().upper()\n",
    "        labels.append(label)\n",
    "    return {\"tokens\": tokens, \"labels\": labels}\n",
    "\n",
    "# â–¶ï¸ Start labeling\n",
    "for i in range(NUM_TO_LABEL):\n",
    "    print(f\"\\nğŸ”· Sample {i + 1}/{NUM_TO_LABEL}\")\n",
    "    tokens = df.iloc[i][\"tokens\"]\n",
    "    labeled_sample = label_sample(tokens)\n",
    "    labeled_data.append(labeled_sample)\n",
    "\n",
    "# ğŸ’¾ Save to CoNLL format\n",
    "def save_conll(data, filepath):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            for token, label in zip(item[\"tokens\"], item[\"labels\"]):\n",
    "                f.write(f\"{token}\\t{label}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "save_conll(labeled_data, \"data/labeled/amharic_ner.conll\")\n",
    "print(\"âœ… Done labeling. Saved to: data/labeled/amharic_ner.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    ['One', 'Step', 'Hair', 'Dryer', 'Styler', 'áŠ¨áˆ­áˆ', 'áˆˆáˆ˜áˆµáˆ«á‰µ', 'áˆˆáˆ›áˆˆáˆµáˆˆáˆµ', 'áŠ¥áŠ•á‹²áˆáˆ', 'áˆˆáˆ›á‹µáˆ¨á‰…', 'á‹¨áˆšá‹«áŒˆáˆˆáŒáˆ'],\n",
    "    ['áˆ›áˆµáˆáŠ•áŒ áˆªá‹«á‹áŠ•', 'á‰°áŒ­áŠá‹', 'áŠ áˆáŠ‘áŠ‘', 'á‹­áˆ˜á‹áŒˆá‰¡', 'á¤', '10', 'á‰…áŠ“áˆ½', 'á‹«áŒáŠ™', '!', '!'],\n",
    "    # Add more samples as needed\n",
    "]\n",
    "\n",
    "# Print each sample in markdown style for labeling\n",
    "for i, tokens in enumerate(samples, start=1):\n",
    "    print(f\"ğŸŸ¦ Sample {i}:\")\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print()  # Blank line for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a154891",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"ğŸ¯ Three-layer Baby Milk Powder Container \n",
    "ğŸ’¯ High Quality \n",
    "\n",
    "ğŸ‘ Three Layer No-Spill Baby Feeding Milk Powder Food Dispenser. A perfect storage for travel or home use.\n",
    "\n",
    "ğŸ‘áŠ¥áŠ“á‰µ áˆáŒ‡áŠ• á‹­á‹› á‹¨á‰°áˆˆá‹«á‹¨ á‰¦á‰³ áˆµá‰µáŠ•á‰€áˆ³á‰€áˆµ\n",
    "á‹¨á‹±á‰„á‰µ á‹ˆá‰°á‰µ á‹¨áˆ˜áˆ³áˆ°áˆ‰á‰µáŠ• áŠ áˆµáˆáˆ‹áŒŠ á‹¨áˆáŒ†á‰½ áˆáŒá‰¥ á‹­á‹ áˆˆáˆ˜áŠ•á‰€áˆ³á‰€áˆµ á‹¨áˆšáˆ¨á‹³ 3 á“áˆ­á‰²áˆ½áŠ• á‹«áˆˆá‹ áŠ áˆªá áŠ®áŠ•á‰´áŠáˆ­\n",
    "\n",
    "á‹‹áŒ‹á¦ 500á‰¥áˆ­\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ads_text = \"\"\"\n",
    "ğŸ“Œ Only baby 3in1 double bottle milk warmer,sterilizer,food steamer\n",
    "\n",
    "âš¡ï¸áˆˆáˆ•áƒáŠ• á‹ˆá‰°á‰µ áˆ›áˆá‰‚á‹«\n",
    "âš ï¸ á‰ á‰°áŒ¨áˆ›áˆª áˆáŒá‰¥ áˆˆáˆ˜á‰€á‰€áˆ á‹¨áˆšáˆ†áŠ• \n",
    "\n",
    "á‹‹áŒ‹á¦  ğŸ’²ğŸ· 3000  á‰¥áˆ­\n",
    "\n",
    "â™¦ï¸á‹áˆµáŠ• ááˆ¬ áŠá‹ á‹«áˆˆá‹ğŸ”¥ğŸ”¥ğŸ”¥\n",
    "\n",
    "ğŸ¢ áŠ á‹µáˆ«áˆ»ğŸ‘‰\n",
    "\n",
    "ğŸ“â™¦ï¸#áˆ˜áŒˆáŠ“áŠ›_áˆ˜áˆ°áˆ¨á‰µ_á‹°á‹áˆ­_áˆáˆ_áˆáˆˆá‰°áŠ›_áá‰… á‰¢áˆ® á‰. S05/S06\n",
    "\n",
    "     ğŸ’§ğŸ’§ğŸ’§ğŸ’§\n",
    "\n",
    "    ğŸ“² 0902660722\n",
    "    ğŸ“² 0928460606 \n",
    "\n",
    "ğŸ”–\n",
    "ğŸ’¬á‰ Telegram áˆˆáˆ›á‹˜á‹ â¤µï¸ á‹­áŒ á‰€áˆ™ğŸ”½\n",
    "\n",
    "@zemencallcenter \n",
    "@zemenexpressadmin\n",
    "\n",
    "áˆˆá‰°áŒ¨áˆ›áˆª áˆ›á‰¥áˆ«áˆªá‹« á‹¨á‰´áˆŒáŒáˆ«áˆ áŒˆáƒá‰½áŠ•â¤µï¸\n",
    "https://telegram.me/zemenexpress\n",
    "\n",
    "ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\n",
    "\n",
    "ğŸ“Œ Mini Pocket UV Umbrella\n",
    "\n",
    "ğŸ‘ á‹¨á‰€áˆˆáˆ áŠ áˆ›áˆ«áŒ­ áŠ áˆ‹á‰¸á‹\n",
    "\n",
    "â˜”á‰ áŒ£áˆ á‰€áˆ‹áˆá£ áˆˆáˆ˜á‹«á‹ áˆá‰¹ áŒ¥áˆ‹ â˜”ï¸\n",
    "â˜”á‰ á‰µáŠ•áˆ½ á‹¨áŠ¥áŒ… á‰¦áˆ­áˆ³ á‹ˆá‹­áˆ á‰ áŠªáˆµ áˆ˜á‹«á‹ á‹¨áˆšá‰½áˆâ˜”\n",
    "\n",
    "#Specifications: \n",
    "ğŸ‘Compact & Light-Weight\n",
    "ğŸ‘Unique Design\n",
    "ğŸ‘UV protection\n",
    "\n",
    " á‹‹áŒ‹á¦  ğŸ’µğŸ·  1000á‰¥áˆ­\n",
    "\n",
    "â™¦ï¸á‹áˆµáŠ• ááˆ¬ áŠá‹ á‹«áˆˆá‹ ğŸ”¥ğŸ”¥ğŸ”¥\n",
    "\n",
    "ğŸ¢ áŠ á‹µáˆ«áˆ»ğŸ‘‰\n",
    "\n",
    "ğŸ“â™¦ï¸#áˆ˜áŒˆáŠ“áŠ›_áˆ˜áˆ°áˆ¨á‰µ_á‹°á‹áˆ­_áˆáˆ_áˆáˆˆá‰°áŠ›_áá‰… á‰¢áˆ® á‰. S05/S06\n",
    "\n",
    "     ğŸ’§ğŸ’§ğŸ’§ğŸ’§\n",
    "\n",
    "    ğŸ“² 0902660722\n",
    "    ğŸ“² 0928460606 \n",
    "\n",
    "ğŸ”–\n",
    "ğŸ’¬á‰ Telegram áˆˆáˆ›á‹˜á‹ â¤µï¸ á‹­áŒ á‰€áˆ™ğŸ”½\n",
    "\n",
    "@zemencallcenter \n",
    "@zemenexpressadmin\n",
    "\n",
    "áˆˆá‰°áŒ¨áˆ›áˆª áˆ›á‰¥áˆ«áˆªá‹« á‹¨á‰´áˆŒáŒáˆ«áˆ áŒˆáƒá‰½áŠ•â¤µï¸\n",
    "https://telegram.me/zemenexpress\n",
    "\"\"\"\n",
    "\n",
    "# Find all lines starting with ğŸ“Œ (likely product titles)\n",
    "product_clues = re.findall(r\"ğŸ“Œ.*?(?=\\n)\", ads_text)\n",
    "\n",
    "print(\"Number of product samples:\", len(product_clues))\n",
    "print(\"Samples found:\")\n",
    "for clue in product_clues:\n",
    "    print(\"-\", clue)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
